{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LSTM examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code for the lecture series \"Machine Learning for Physicists\" by Florian Marquardt\n",
    "\n",
    "Lecture 6\n",
    "\n",
    "See https://machine-learning-for-physicists.org and the current course website linked there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to:\n",
    "- train a recurrent (LSTM) network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras library. Also import some of the layers, so we do not need to\n",
    "# write things like \"layers.Dense\", but can just write \"Dense\" instead\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# Import the numpy library for matrix manipulations etc.\n",
    "from numpy import *\n",
    "\n",
    "# Set up the graphics by importing the matplotlib plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A net that can recall a number (that it has been told before), when asked to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_memory_net():\n",
    "    global rnn, timesteps\n",
    "    rnn = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    rnn.add(LSTM(5, batch_input_shape=(None, timesteps, 3), return_sequences=True))\n",
    "    rnn.add(LSTM(2, return_sequences=True))\n",
    "    rnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_batch():\n",
    "    global batchsize, timesteps\n",
    "    \n",
    "    observations=zeros([batchsize,timesteps,3])\n",
    "    desired_output=zeros([batchsize,timesteps,2])\n",
    "    \n",
    "    tell_position=random.randint(int(timesteps/2),size=batchsize)\n",
    "    ask_position=int(timesteps/2)+1+random.randint(int(timesteps/2)-1,size=batchsize)\n",
    "    \n",
    "    # mark input-slot 0 with 1 at the tell_position:\n",
    "    observations[range(batchsize),tell_position,0]=1\n",
    "    # write the value to be memorized into input-slot 1\n",
    "    memorize_numbers=random.random(batchsize)\n",
    "    observations[range(batchsize),tell_position,1]=memorize_numbers\n",
    "    # mark input-slot 2 with 1 at the ask_position\n",
    "    observations[range(batchsize),ask_position,2]=1\n",
    "    \n",
    "    desired_output[range(batchsize),ask_position,0]=memorize_numbers\n",
    "    return(observations,desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timesteps=20\n",
    "\n",
    "\n",
    "init_memory_net()\n",
    "\n",
    "batchsize=1\n",
    "test_observations,test_target=produce_batch()\n",
    "\n",
    "batchsize=20\n",
    "epochs=300\n",
    "\n",
    "test_output=zeros([timesteps,epochs])\n",
    "\n",
    "for k in range(epochs):\n",
    "    input_observations,output_targets=produce_batch()\n",
    "    rnn.train_on_batch(input_observations,output_targets)\n",
    "    test_output[:,k]=rnn.predict_on_batch(test_observations)[0,:,0]\n",
    "    print(\"epoch: \", k, \" deviation: \", \"{:1.3f}\".format(sum((test_output[:,k]-test_target[0,:,0])**2)), end=\"      \\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(7,5))\n",
    "plt.imshow(test_output,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchsize=30\n",
    "test_observations,test_target=produce_batch()\n",
    "test_output=zeros([batchsize,timesteps])\n",
    "\n",
    "test_output[:,:]=rnn.predict_on_batch(test_observations)[:,:,0]\n",
    "\n",
    "fig=plt.figure(figsize=(3,2))\n",
    "plt.imshow(test_target[:,:,0],vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(3,2))\n",
    "plt.imshow(test_output,vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(\"Deviation: \", sum((test_output-test_target[:,:,0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_batch_tell_ask_twice():\n",
    "    global batchsize, timesteps\n",
    "    \n",
    "    observations=zeros([batchsize,timesteps,3])\n",
    "    desired_output=zeros([batchsize,timesteps,2])\n",
    "    \n",
    "    tell_position=random.randint(int(timesteps/2),size=batchsize)\n",
    "    ask_position=int(timesteps/2)+1+random.randint(int(timesteps/4)-2,size=batchsize)\n",
    "    ask_position2=ask_position+1+random.randint(int(timesteps/4)-2,size=batchsize)\n",
    "    \n",
    "    # mark input-slot 0 with 1 at the tell_position:\n",
    "    observations[range(batchsize),tell_position,0]=1\n",
    "    # write the value to be memorized into input-slot 1\n",
    "    memorize_numbers=random.random(batchsize)\n",
    "    observations[range(batchsize),tell_position,1]=memorize_numbers\n",
    "    # mark input-slot 2 with 1 at the ask_position\n",
    "    observations[range(batchsize),ask_position,2]=1\n",
    "    observations[range(batchsize),ask_position2,2]=1\n",
    "    \n",
    "    desired_output[range(batchsize),ask_position,0]=memorize_numbers\n",
    "    desired_output[range(batchsize),ask_position2,0]=memorize_numbers\n",
    "    return(observations,desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=30\n",
    "test_observations,test_target=produce_batch_tell_ask_twice()\n",
    "test_output=zeros([batchsize,timesteps])\n",
    "\n",
    "test_output[:,:]=rnn.predict_on_batch(test_observations)[:,:,0]\n",
    "\n",
    "fig=plt.figure(figsize=(4,3))\n",
    "plt.imshow(test_target[:,:,0],vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(4,3))\n",
    "plt.imshow(test_output,vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(\"Deviation: \", sum((test_output-test_target[:,:,0])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_memory_net_powerful():\n",
    "    global rnn, batchsize, timesteps\n",
    "    rnn = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    rnn.add(LSTM(20, batch_input_shape=(None, timesteps, 3), return_sequences=True))\n",
    "    rnn.add(LSTM(2, return_sequences=True))\n",
    "    rnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init_memory_net_powerful()\n",
    "\n",
    "timesteps=20\n",
    "\n",
    "batchsize=1\n",
    "test_observations,test_target=produce_batch()\n",
    "\n",
    "batchsize=20\n",
    "epochs=300\n",
    "\n",
    "test_output=zeros([timesteps,epochs])\n",
    "\n",
    "for k in range(epochs):\n",
    "    input_observations,output_targets=produce_batch()\n",
    "    rnn.train_on_batch(input_observations,output_targets)\n",
    "    test_output[:,k]=rnn.predict_on_batch(test_observations)[0,:,0]\n",
    "    print(\"\\r epoch: \", k, \" deviation: \", sum((test_output[:,k]-test_target[0,:,0])**2), end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10,7))\n",
    "plt.imshow(test_output,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=30\n",
    "test_observations,test_target=produce_batch()\n",
    "test_output=zeros([batchsize,timesteps])\n",
    "\n",
    "test_output[:,:]=rnn.predict_on_batch(test_observations)[:,:,0]\n",
    "\n",
    "fig=plt.figure(figsize=(5,4))\n",
    "plt.imshow(test_target[:,:,0],vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(5,4))\n",
    "plt.imshow(test_output,vmax=1.0,vmin=0.0,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print(\"Deviation: \", sum((test_output-test_target[:,:,0])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countdown-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A net that counts down: At some random time, it is told a number, and then it outputs a 'one' after this number of steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_count_net():\n",
    "    global rnn, batchsize, timesteps\n",
    "    global firstLSTMlayer\n",
    "    rnn = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    firstLSTMlayer=LSTM(2, batch_input_shape=(None, timesteps, 2), return_sequences=True)\n",
    "    rnn.add(firstLSTMlayer)\n",
    "    rnn.add(LSTM(2, return_sequences=True))\n",
    "    rnn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_batch_counting():\n",
    "    global batchsize, timesteps\n",
    "    \n",
    "    observations=zeros([batchsize,timesteps,2])\n",
    "    desired_output=zeros([batchsize,timesteps,2])\n",
    "    \n",
    "    tell_position=random.randint(int(timesteps/2),size=batchsize)\n",
    "    count_position=random.randint(int(timesteps/2)-1,size=batchsize)\n",
    "    expect_position=tell_position+count_position\n",
    "    \n",
    "    # mark input-slot 0 with 1 at the tell_position:\n",
    "    observations[range(batchsize),tell_position,0]=1\n",
    "    # write the counter value\n",
    "    observations[range(batchsize),tell_position,1]=count_position\n",
    "    \n",
    "    desired_output[range(batchsize),expect_position,0]=1\n",
    "    return(observations,desired_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timesteps=20\n",
    "\n",
    "\n",
    "init_count_net()\n",
    "\n",
    "\n",
    "batchsize=1\n",
    "test_observations,test_target=produce_batch_counting()\n",
    "\n",
    "batchsize=20\n",
    "epochs=300\n",
    "\n",
    "test_output=zeros([timesteps,epochs])\n",
    "\n",
    "for k in range(epochs):\n",
    "    input_observations,output_targets=produce_batch_counting()\n",
    "    rnn.train_on_batch(input_observations,output_targets)\n",
    "    test_output[:,k]=rnn.predict_on_batch(test_observations)[0,:,0]\n",
    "    print(\"epoch: \", k, \" deviation: \", \"{:1.3f}\".format(sum((test_output[:,k]-test_target[0,:,0])**2)), end=\"    \\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(7,5))\n",
    "plt.imshow(test_output,origin='lower',interpolation='nearest',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now: try to inspect output of LSTM neurons at intermediate times. This is also a nice example of how to use some smart keras functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "# get a function that represents the mapping from the \n",
    "# network inputs to the neuron output values of the first LSTM layer:\n",
    "neuron_values = Model([rnn.inputs], [firstLSTMlayer.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize=1\n",
    "test_observations,test_target=produce_batch_counting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_values=neuron_values.predict_on_batch([test_observations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(the_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(the_values[0,:,:],interpolation='nearest',origin='lower',aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
