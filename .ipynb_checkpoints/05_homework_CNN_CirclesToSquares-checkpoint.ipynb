{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Neural Networks to do image transformations (circles to squares, in this case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code for the lecture series \"Machine Learning for Physicists\" by Florian Marquardt\n",
    "\n",
    "Lecture 4, Homework (this is discussed in session 5)\n",
    "\n",
    "See https://machine-learning-for-physicists.org and the current course website linked there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to:\n",
    "- train a network to turn circles into squares inside an image\n",
    "\n",
    "The networks are 2D convolutional networks, with the same input and output dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports: numpy and matplotlib and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras: Sequential is the neural-network class, Dense is\n",
    "# the standard network layer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras import optimizers # to choose more advanced optimizers like 'adam'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization routines:\n",
    "# slightly changed for this notebook\n",
    "# to display both test in / test target and test prediction\n",
    "\n",
    "def visualize_CNN_training(network,\n",
    "                               image_generator, resolution,\n",
    "                    steps=100, batchsize=10,\n",
    "                              visualize_nsteps=1, plot_img_pixels=3,\n",
    "                          plot_img_cols=10,\n",
    "                          plot_img_rows=5,\n",
    "                          show_intermediate_layers=True,\n",
    "                          num_tests=1):\n",
    "    \"\"\"\n",
    "    Visualize the training of a (2D) convolutional neural network autoencoder.\n",
    "    \n",
    "    network is the network that you have defined using keras.\n",
    "    \n",
    "    'resolution' (called M below) is the image resolution in pixels\n",
    "    \n",
    "    image_generator is the name of a function that\n",
    "    is called like\n",
    "        image_generator(batchsize,x,y)\n",
    "    and which has to return an array of shape\n",
    "        [batchsize,M,M]\n",
    "    that contains randomly generated MxM images (e.g. randomly\n",
    "    placed circles or whatever you want to consider). The\n",
    "    MxM arrays x and y are already filled with coordinates between -1 and 1.\n",
    "    \n",
    "    An example that returns images of randomly placed circles:\n",
    "    \n",
    "    def my_generator(batchsize,x,y):\n",
    "        R=np.random.uniform(size=batchsize)\n",
    "        x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) )\n",
    "\n",
    "   \n",
    "    steps is the number of training steps\n",
    "    \n",
    "    batchsize is the number of samples per training step\n",
    "            \n",
    "    visualize_n_steps>1 means skip some steps before\n",
    "    visualizing again (can speed up things)\n",
    "    \n",
    "    show_intermediate_layers==True means show the intermediate activations.\n",
    "    Otherwise show the weights!\n",
    "    \n",
    "    These are always shown in the upper left corner, as a tiled image,\n",
    "    whose properties are determined by:\n",
    "        plot_img_pixels: the resolution for each of the image tiles\n",
    "        plot_img_cols  : the number of columns of images\n",
    "        plot_img_rows  : the number of rows of images\n",
    "    Images (activations or weights) that are larger will be cut off.\n",
    "    If there are more images than fit, the rest will be left out.\n",
    "    The lowest layer starts in the bottom left. For activations, for\n",
    "    each layer one runs through all the channels, and then the images\n",
    "    for the next layer will start. Likewise for weights.\n",
    "    \"\"\"\n",
    "    global y_test, y_test_out, y_test_target\n",
    "    \n",
    "    M=resolution\n",
    "        \n",
    "    vals=np.linspace(-1,1,M)\n",
    "    x,y=np.meshgrid(vals,vals)\n",
    "    \n",
    "    y_test=np.zeros([num_tests,M,M,1])\n",
    "    y_test_target=np.zeros([num_tests,M,M,1])\n",
    "    y_test[:,:,:,0],y_test_target[:,:,:,0]=image_generator(num_tests,x,y)\n",
    "    \n",
    "    y_in=np.zeros([batchsize,M,M,1])\n",
    "    y_target=np.zeros([batchsize,M,M,1])\n",
    "\n",
    "    costs=np.zeros(steps)\n",
    "    extractor=get_layer_activation_extractor(network)\n",
    "    \n",
    "    for j in range(steps):\n",
    "        # produce samples:\n",
    "        y_in[:,:,:,0],y_target[:,:,:,0]=image_generator(batchsize,x,y)\n",
    "        \n",
    "        # do one training step on this batch of samples:\n",
    "        costs[j]=network.train_on_batch(y_in,y_target)\n",
    "        \n",
    "        # now visualize the updated network:\n",
    "        if j%visualize_nsteps==0:\n",
    "            clear_output(wait=True) # for animation\n",
    "            if j>10:\n",
    "                cost_max=np.average(costs[0:j])*1.5\n",
    "            else:\n",
    "                cost_max=costs[0]\n",
    "            \n",
    "            # nice layout (needs matplotlib v3)\n",
    "            fig=plt.figure(constrained_layout=True,figsize=(8,4))\n",
    "            gs=fig.add_gridspec(ncols=8,nrows=4)\n",
    "            filter_plot=fig.add_subplot(gs[0:3,0:4])\n",
    "            cost_plot=fig.add_subplot(gs[3,0:4])\n",
    "            test_in_plot=fig.add_subplot(gs[0:2,4:6])\n",
    "            test_target_plot=fig.add_subplot(gs[0:2,6:8])\n",
    "            test_out_plot=fig.add_subplot(gs[2:,6:8])\n",
    "\n",
    "            cost_plot.plot(costs)\n",
    "            cost_plot.set_ylim([0,cost_max])\n",
    "            \n",
    "            # test the network on a fixed test image!\n",
    "            y_test_out=network.predict_on_batch(y_test)\n",
    "            test_in_plot.imshow(y_test[0,:,:,0],origin='lower')\n",
    "            test_out_plot.imshow(y_test_out[0,:,:,0],origin='lower')\n",
    "            test_target_plot.imshow(y_test_target[0,:,:,0],origin='lower')\n",
    "            test_in_plot.axis('off')\n",
    "            test_out_plot.axis('off')\n",
    "            test_target_plot.axis('off')\n",
    "            \n",
    "            if show_intermediate_layers:\n",
    "                features=extractor(y_test)\n",
    "                n1=0; n2=0\n",
    "                max_n1=plot_img_rows\n",
    "                max_n2=plot_img_cols\n",
    "                pix=plot_img_pixels\n",
    "                img=np.full([(pix+1)*max_n1,(pix+1)*max_n2],1.0)\n",
    "                for feature in features:\n",
    "                    for m in range(feature.shape[-1]):\n",
    "                        w=feature[0,:,:,m]\n",
    "                        ws=np.shape(w)\n",
    "                        if n1<max_n1 and n2<max_n2:\n",
    "                            W=np.zeros([pix,pix])\n",
    "                            if ws[0]<pix:\n",
    "                                W[0:ws[0],0:ws[0]]=w[:,:]\n",
    "                            else:\n",
    "                                W[:,:]=w[0:pix,0:pix]                            \n",
    "                            img[n1*(pix+1):(n1+1)*(pix+1)-1,n2*(pix+1):(n2+1)*(pix+1)-1]=W\n",
    "                            n2+=1\n",
    "                            if n2>=max_n2:\n",
    "                                n2=0\n",
    "                                n1+=1                \n",
    "            else: # rather, we want the weights! (filters)\n",
    "                n1=0; n2=0\n",
    "                max_n1=plot_img_rows\n",
    "                max_n2=plot_img_cols\n",
    "                pix=plot_img_pixels\n",
    "                img=np.zeros([(pix+1)*max_n1,(pix+1)*max_n2])\n",
    "                for ly in network.layers:\n",
    "                    w=ly.get_weights()\n",
    "                    if w!=[]:\n",
    "                        w=w[0]\n",
    "                        ws=np.shape(w)\n",
    "                        for k1 in range(ws[2]):\n",
    "                            for k2 in range(ws[3]):\n",
    "                                if n1<max_n1 and n2<max_n2:\n",
    "                                    W=np.zeros([pix,pix])\n",
    "                                    if ws[0]<pix:\n",
    "                                        W[0:ws[0],0:ws[0]]=w[:,:,k1,k2]\n",
    "                                    else:\n",
    "                                        W[:,:]=w[0:pix,0:pix,k1,k2]                            \n",
    "                                    img[n1*(pix+1):(n1+1)*(pix+1)-1,n2*(pix+1):(n2+1)*(pix+1)-1]=W\n",
    "                                    n2+=1\n",
    "                                    if n2>=max_n2:\n",
    "                                        n2=0\n",
    "                                        n1+=1\n",
    "            filter_plot.imshow(img,origin='lower')\n",
    "            filter_plot.axis('off')\n",
    "            plt.show()\n",
    "    print(\"Final cost value (averaged over last 50 batches): \", np.average(costs[-50:]))\n",
    "\n",
    "\n",
    "def print_layers(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get a print-out of\n",
    "    the layer sizes. Shapes shown are (batchsize,pixels,pixels,channels).\n",
    "    After a call to the visualization routine, y_target will contain\n",
    "    the last set of training images, so you could feed those in here.\n",
    "    \"\"\"\n",
    "    layer_features=get_layer_activations(network,y_in)\n",
    "    for idx,feature in enumerate(layer_features):\n",
    "        s=np.shape(feature)\n",
    "        print(\"Layer \"+str(idx)+\": \"+str(s[1]*s[2]*s[3])+\" neurons / \", s)\n",
    "\n",
    "def get_layer_activation_extractor(network):\n",
    "    return(Model(inputs=network.inputs,\n",
    "                            outputs=[layer.output for layer in network.layers]))\n",
    "\n",
    "def get_layer_activations(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get the intermediate \n",
    "    layer neuron values. These are returned in a list, with one\n",
    "    entry for each layer (the entries are arrays).\n",
    "    \"\"\"\n",
    "    extractor=get_layer_activation_extractor(network)\n",
    "    layer_features = extractor(y_in)\n",
    "    return(layer_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning randomly placed circles into squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(batchsize,x,y):\n",
    "    \"\"\"\n",
    "    Place some circles randomly, then place (for the\n",
    "    target image) squares at the same positions, with\n",
    "    the same size\n",
    "    \"\"\"\n",
    "    global num_circles\n",
    "\n",
    "    M=np.shape(x)[0]\n",
    "    theCircles=np.zeros([batchsize,M,M])\n",
    "    theSquares=np.zeros([batchsize,M,M])\n",
    "    \n",
    "    for j in range(num_circles):\n",
    "        R=np.random.uniform(size=batchsize)*0.5\n",
    "        x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        theCircles+=1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2)\n",
    "        theSquares+=1.0*(np.abs(x[None,:,:]-x0[:,None,None])< R[:,None,None])*(np.abs(y[None,:,:]-y0[:,None,None])< R[:,None,None])\n",
    "    return theCircles,theSquares\n",
    "\n",
    "num_circles=5\n",
    "\n",
    "Net=Sequential()\n",
    "num_channels=20\n",
    "kernel_size=5\n",
    "num_layers=4\n",
    "\n",
    "for j in range(num_layers):\n",
    "    if j==0:\n",
    "        the_input_shape=(None,None,1)\n",
    "    else:\n",
    "        the_input_shape=(None,None,num_channels)\n",
    "    Net.add(Conv2D(num_channels,kernel_size,input_shape=the_input_shape,\n",
    "               activation=\"relu\",padding='same'))\n",
    "Net.add(Conv2D(1,kernel_size,activation=\"linear\",padding='same'))\n",
    "Net.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this for at least 300 steps (batchsize 10) to\n",
    "# get decent results\n",
    "visualize_CNN_training(Net, my_generator, 50,\n",
    "                    steps=100, batchsize=10,\n",
    "                              visualize_nsteps=10,\n",
    "                      plot_img_pixels=50, \n",
    "                       plot_img_rows=6, plot_img_cols=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell before, but with num_tests=5 option\n",
    "# then run this cell!\n",
    "#\n",
    "# show the typical test images (these are available\n",
    "# in the global variable y_test after calling the visualization routine)\n",
    "fig,ax=plt.subplots(ncols=5,nrows=3,figsize=(5,3))\n",
    "for j in range(5):\n",
    "    ax[0,j].imshow(y_test[j,:,:,0],origin='lower') # the last training images...\n",
    "    ax[0,j].axis('off')\n",
    "    ax[1,j].imshow(y_test_target[j,:,:,0],origin='lower') # the last training images...\n",
    "    ax[1,j].axis('off')\n",
    "    ax[2,j].imshow(y_test_out[j,:,:,0],origin='lower') # the last training images...\n",
    "    ax[2,j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
